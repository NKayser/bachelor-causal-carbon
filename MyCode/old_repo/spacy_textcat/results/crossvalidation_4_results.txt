============================== crossvalidation ==============================
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy init fill-config configs/base_config.cfg configs/config.cfg
✔ Auto-filled config with all values
✔ Saved config
configs\config.cfg
You can now add your data and train your pipeline:
python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' scripts/make_corpus_for_cross_validation.py
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2999/2999 [00:04<00:00, 705.76it/s]
Bucket 0:       22 pos, 37 neg
Bucket 1:       19 pos, 22 neg
Bucket 2:       24 pos, 28 neg
Bucket 3:       20 pos, 31 neg
Bucket 4:       25 pos, 35 neg
Bucket 5:       20 pos, 25 neg
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy train configs/config.cfg --gpu-id 0 -o models/cval_0 --paths.train corpus/textcat_cval_0_train.spacy --paths.dev corpus/textcat_cval_0_dev.spacy
ℹ Saving to output directory: models\cval_0
ℹ Using GPU: 0

=========================== Initializing pipeline ===========================
[2022-11-29 15:34:17,164] [INFO] Set up nlp object from config
[2022-11-29 15:34:17,172] [INFO] Pipeline: ['transformer', 'textcat']
[2022-11-29 15:34:17,175] [INFO] Created vocabulary
[2022-11-29 15:34:17,175] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-11-29 15:34:27,581] [INFO] Initialized pipeline components: ['transformer', 'textcat']
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['transformer', 'textcat']
ℹ Initial learn rate: 0.0
E    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE
---  ------  -------------  ------------  ----------  ------
  0       0           0.00          0.25       31.67    0.32
  2     200           0.02         45.97       34.92    0.35
  5     400           1.15         32.39       82.93    0.83
  7     600           0.16         18.19       34.92    0.35
 10     800           0.16         50.42       34.92    0.35
 13    1000           0.51         57.19       34.92    0.35
 15    1200           0.42         55.65       34.92    0.35
 18    1400           0.65         55.30       34.92    0.35
 21    1600           0.64         54.88       34.92    0.35
 23    1800           0.36         51.44       34.92    0.35
 26    2000           0.12         51.34       34.92    0.35
✔ Saved pipeline to output directory
models\cval_0\model-last
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy train configs/config.cfg --gpu-id 0 -o models/cval_1 --paths.train corpus/textcat_cval_1_train.spacy --paths.dev corpus/textcat_cval_1_dev.spacy
ℹ Saving to output directory: models\cval_1
ℹ Using GPU: 0

=========================== Initializing pipeline ===========================
[2022-11-29 15:43:51,163] [INFO] Set up nlp object from config
[2022-11-29 15:43:51,171] [INFO] Pipeline: ['transformer', 'textcat']
[2022-11-29 15:43:51,173] [INFO] Created vocabulary
[2022-11-29 15:43:51,174] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-11-29 15:44:01,340] [INFO] Initialized pipeline components: ['transformer', 'textcat']
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['transformer', 'textcat']
ℹ Initial learn rate: 0.0
E    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE
---  ------  -------------  ------------  ----------  ------
  0       0           0.00          0.25       31.58    0.32
  2     200           0.01         49.94       35.00    0.35
  5     400           0.05         45.22       35.00    0.35
  8     600           0.31         52.51       35.00    0.35
 11     800           0.91         55.20       35.00    0.35
 13    1000           1.88         50.40       35.00    0.35
 16    1200           1.50         49.76       35.00    0.35
 19    1400           2.12         56.89       35.00    0.35
 22    1600           2.48         52.94       35.00    0.35
 24    1800           2.16         52.49       35.00    0.35
✔ Saved pipeline to output directory
models\cval_1\model-last
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy train configs/config.cfg --gpu-id 0 -o models/cval_2 --paths.train corpus/textcat_cval_2_train.spacy --paths.dev corpus/textcat_cval_2_dev.spacy
ℹ Saving to output directory: models\cval_2
ℹ Using GPU: 0

=========================== Initializing pipeline ===========================
[2022-11-29 15:52:49,820] [INFO] Set up nlp object from config
[2022-11-29 15:52:49,828] [INFO] Pipeline: ['transformer', 'textcat']
[2022-11-29 15:52:49,831] [INFO] Created vocabulary
[2022-11-29 15:52:49,832] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-11-29 15:52:59,711] [INFO] Initialized pipeline components: ['transformer', 'textcat']
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['transformer', 'textcat']
ℹ Initial learn rate: 0.0
E    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE
---  ------  -------------  ------------  ----------  ------
  0       0           0.00          0.25       28.17    0.28
  2     200           0.01         43.36       79.15    0.79
  5     400           0.33         36.39       37.80    0.38
  8     600           0.08         48.49       37.80    0.38
 11     800           0.15         54.16       37.80    0.38
 14    1000           0.11         53.05       37.80    0.38
 17    1200           0.51         51.97       37.80    0.38
 20    1400           1.37         53.01       37.80    0.38
 23    1600           1.12         54.12       37.80    0.38
 26    1800           0.13         49.57       37.80    0.38
✔ Saved pipeline to output directory
models\cval_2\model-last
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy train configs/config.cfg --gpu-id 0 -o models/cval_3 --paths.train corpus/textcat_cval_3_train.spacy --paths.dev corpus/textcat_cval_3_dev.spacy
ℹ Saving to output directory: models\cval_3
ℹ Using GPU: 0

=========================== Initializing pipeline ===========================
[2022-11-29 16:01:51,379] [INFO] Set up nlp object from config
[2022-11-29 16:01:51,387] [INFO] Pipeline: ['transformer', 'textcat']
[2022-11-29 16:01:51,390] [INFO] Created vocabulary
[2022-11-29 16:01:51,391] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-11-29 16:02:01,443] [INFO] Initialized pipeline components: ['transformer', 'textcat']
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['transformer', 'textcat']
ℹ Initial learn rate: 0.0
E    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE
---  ------  -------------  ------------  ----------  ------
  0       0           0.00          0.25       29.41    0.29
  2     200           0.07         45.77       72.82    0.73
  5     400           4.37         10.93       91.47    0.91
  8     600           0.44         51.03       29.41    0.29
 11     800           0.23         58.11       36.84    0.37
 14    1000           0.18         56.95       36.84    0.37
 17    1200           0.21         54.05       36.84    0.37
 20    1400           0.10         55.34       36.84    0.37
 23    1600           0.32         57.36       36.84    0.37
 26    1800           0.80         57.24       36.84    0.37
 29    2000           0.16         53.88       36.84    0.37
✔ Saved pipeline to output directory
models\cval_3\model-last
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy train configs/config.cfg --gpu-id 0 -o models/cval_4 --paths.train corpus/textcat_cval_4_train.spacy --paths.dev corpus/textcat_cval_4_dev.spacy
ℹ Saving to output directory: models\cval_4
ℹ Using GPU: 0

=========================== Initializing pipeline ===========================
[2022-11-29 16:11:57,502] [INFO] Set up nlp object from config
[2022-11-29 16:11:57,510] [INFO] Pipeline: ['transformer', 'textcat']
[2022-11-29 16:11:57,512] [INFO] Created vocabulary
[2022-11-29 16:11:57,513] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-11-29 16:12:07,918] [INFO] Initialized pipeline components: ['transformer', 'textcat']
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['transformer', 'textcat']
ℹ Initial learn rate: 0.0
E    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE
---  ------  -------------  ------------  ----------  ------
  0       0           0.00          0.25       30.77    0.31
  2     200           0.26         47.54       76.37    0.76
  5     400           0.08         35.53       77.77    0.78
  8     600           0.16         50.13       35.71    0.36
 11     800           3.77         47.28       35.71    0.36
 13    1000           0.17         27.24       80.00    0.80
 16    1200           1.18         27.88       80.00    0.80
 19    1400           0.21         25.95       80.00    0.80
 22    1600           0.34         28.97       80.00    0.80
 24    1800           0.13         26.81       80.00    0.80
 27    2000           0.16         25.49       80.00    0.80
 30    2200           0.25         29.63       80.00    0.80
 33    2400           0.22         25.89       80.00    0.80
 35    2600           0.29         24.78       80.00    0.80
✔ Saved pipeline to output directory
models\cval_4\model-last
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy train configs/config.cfg --gpu-id 0 -o models/cval_5 --paths.train corpus/textcat_cval_5_train.spacy --paths.dev corpus/textcat_cval_5_dev.spacy
ℹ Saving to output directory: models\cval_5
ℹ Using GPU: 0

=========================== Initializing pipeline ===========================
[2022-11-29 16:24:17,927] [INFO] Set up nlp object from config
[2022-11-29 16:24:17,935] [INFO] Pipeline: ['transformer', 'textcat']
[2022-11-29 16:24:17,938] [INFO] Created vocabulary
[2022-11-29 16:24:17,939] [INFO] Finished initializing nlp object
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2022-11-29 16:24:28,206] [INFO] Initialized pipeline components: ['transformer', 'textcat']
✔ Initialized pipeline

============================= Training pipeline =============================
ℹ Pipeline: ['transformer', 'textcat']
ℹ Initial learn rate: 0.0
E    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE
---  ------  -------------  ------------  ----------  ------
  0       0           0.00          0.25       27.16    0.27
  2     200           0.06         42.38       81.09    0.81
  5     400           0.26         29.81       38.54    0.39
  8     600           0.09         49.85       38.54    0.39
 10     800           0.06         49.40       38.54    0.39
 13    1000           0.13         51.03       38.54    0.39
 16    1200           0.23         51.07       38.54    0.39
 18    1400           0.25         48.03       38.54    0.39
 21    1600           0.97         52.30       38.54    0.39
 23    1800           0.14         51.89       38.54    0.39
✔ Saved pipeline to output directory
models\cval_5\model-last
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy evaluate models/cval_0/model-best corpus/textcat_cval_0_test.spacy --gpu-id 0 -o results/cval_0.json
ℹ Using GPU: 0

================================== Results ==================================

TOK                 100.00
TEXTCAT (macro F)   82.65
SPEED               5066


=========================== Textcat F (per label) ===========================

               P       R       F
positive   71.43   90.91   80.00
negative   93.55   78.38   85.29


======================== Textcat ROC AUC (per label) ========================

           ROC AUC
positive      0.85
negative      0.85

✔ Saved results to results\cval_0.json
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy evaluate models/cval_1/model-best corpus/textcat_cval_1_test.spacy --gpu-id 0 -o results/cval_1.json
ℹ Using GPU: 0

================================== Results ==================================

TOK                 100.00
TEXTCAT (macro F)   34.92
SPEED               4986


=========================== Textcat F (per label) ===========================

               P        R       F
positive    0.00     0.00    0.00
negative   53.66   100.00   69.84


======================== Textcat ROC AUC (per label) ========================

           ROC AUC
positive      0.34
negative      0.34

✔ Saved results to results\cval_1.json
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy evaluate models/cval_2/model-best corpus/textcat_cval_2_test.spacy --gpu-id 0 -o results/cval_2.json
ℹ Using GPU: 0

================================== Results ==================================

TOK                 100.00
TEXTCAT (macro F)   77.44
SPEED               4712


=========================== Textcat F (per label) ===========================

               P       R       F
positive   93.33   58.33   71.79
negative   72.97   96.43   83.08


======================== Textcat ROC AUC (per label) ========================

           ROC AUC
positive      0.93
negative      0.93

✔ Saved results to results\cval_2.json
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy evaluate models/cval_3/model-best corpus/textcat_cval_3_test.spacy --gpu-id 0 -o results/cval_3.json
ℹ Using GPU: 0

================================== Results ==================================

TOK                 100.00
TEXTCAT (macro F)   89.95
SPEED               5358


=========================== Textcat F (per label) ===========================

               P       R       F
positive   82.61   95.00   88.37
negative   96.43   87.10   91.53


======================== Textcat ROC AUC (per label) ========================

           ROC AUC
positive      0.98
negative      0.98

✔ Saved results to results\cval_3.json
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy evaluate models/cval_4/model-best corpus/textcat_cval_4_test.spacy --gpu-id 0 -o results/cval_4.json
ℹ Using GPU: 0

================================== Results ==================================

TOK                 100.00
TEXTCAT (macro F)   79.64
SPEED               5003


=========================== Textcat F (per label) ===========================

               P       R       F
positive   74.07   80.00   76.92
negative   84.85   80.00   82.35


======================== Textcat ROC AUC (per label) ========================

           ROC AUC
positive      0.87
negative      0.87

✔ Saved results to results\cval_4.json
Running command: 'C:\Users\Nico\Documents\Bachelor\venv\Scripts\python.exe' -m spacy evaluate models/cval_5/model-best corpus/textcat_cval_5_test.spacy --gpu-id 0 -o results/cval_5.json
ℹ Using GPU: 0

================================== Results ==================================

TOK                 100.00
TEXTCAT (macro F)   81.09
SPEED               5342


=========================== Textcat F (per label) ===========================

               P       R       F
positive   92.86   65.00   76.47
negative   77.42   96.00   85.71


======================== Textcat ROC AUC (per label) ========================

           ROC AUC
positive      0.98
negative      0.98

✔ Saved results to results\cval_5.json
(venv) PS C:\Users\Nico\Documents\Bachelor\MyCode\spacy_textcat>
